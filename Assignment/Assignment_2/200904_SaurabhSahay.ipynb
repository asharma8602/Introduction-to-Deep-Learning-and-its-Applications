{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DL_Stamatics_A2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvFM645NE-D2"
      },
      "source": [
        "# Assignment 2\n",
        "In this assignment, we will go through Perceptron, Linear Classifiers, Loss Functions, Gradient Descent and Back Propagation.\n",
        "\n",
        "\n",
        "PS. this one is not from Stanford's course.\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "## Instructions\n",
        "* This notebook contain blocks of code, you are required to complete those blocks(where required)\n",
        "* You are required to copy this notebook (\"copy to drive\" above) and complete the code.(DO NOT CHANGE THE NAME OF THE FUNCTIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "QLtp15rqE-EU"
      },
      "source": [
        "# Part 1: Perceptron\n",
        "In this section, we will see how to implement a perceptron. Goal would be for you to delve into the mathematics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zao4e-DphaGA"
      },
      "source": [
        "## Intro\n",
        "What's a perceptron? It's an algorithm modelled on biological computational model to classify things into binary classes. It's a supervides learning algorithm, meaning that you need to provide labelled data containing features and the actual classifications. A perceptron would take these features as input and spit out a binary value (0 or 1). While training the model with training data, we try to minimise the error and learn the parameters involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDTUoAd6ixm-"
      },
      "source": [
        "**How does it work?**\\\n",
        "A perceptron is modelled on a biological neuron. A neuron has input dendrites and the output is carried by axons. Similarly, a perceptron takes inputs called \"features\". After processing, a perceptron gives output. For computation, it has a \"weight\" vector which is multipled with feature vector. An activation function is added to introduce some non linearities and the output is given out.\\\n",
        "It can be represented as: $$  f=\\sum_{i=1}^{m} w_ix_i +b$$\n",
        "\n",
        "Let's implement this simple function to give an output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXezofBIgzId"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class perceptron():\n",
        "    def __init__(self,num_input_features=8):\n",
        "        self.weights = np.random.randn(num_input_features)\n",
        "        self.bias = np.random.random()\n",
        "\n",
        "    def activation(self,x):\n",
        "        '''\n",
        "            Implement heavside step activation function here (google ;))\n",
        "        '''\n",
        "        f = np.matmul(self.weights,x) + self.bias\n",
        "        if(f<0.5):\n",
        "          return 0\n",
        "        else:\n",
        "          return 1\n",
        "        pass\n",
        "\n",
        "    def forward(self,x: np.ndarray):\n",
        "        '''\n",
        "            you have random initialized weights and bias\n",
        "            you can access then using `self.weights` and `self.bias`\n",
        "            you should use activation function before returning\n",
        "        \n",
        "            x : input features\n",
        "            return : a binary value as the output of the perceptron \n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        return self.activation(x)\n",
        "        pass\n",
        "        # YOUR CODE HERE"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSKwDFAyocVo"
      },
      "source": [
        "np.random.seed(0)\n",
        "perc = perceptron(8)\n",
        "assert (perc.forward(np.arange(8))==1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "NWTTg1e9r7uM"
      },
      "source": [
        "# Part 2: Linear Classifier\n",
        "In this section, we will see how to implement a linear Classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYDO4GcHr7uM"
      },
      "source": [
        "## Intro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HFvjH06r7uN"
      },
      "source": [
        "**How does it work?**\n",
        "\n",
        "Linear Classifier uses the following function: $$Y = WX+b$$ Where, $W$ is a 2d array of weights with shape (#features, #classes).\n",
        "\n",
        "\n",
        "Let's implement this classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A13CEkGr7uN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearClassifier():\n",
        "    def __init__(self,num_input_features=32,num_classes=5):\n",
        "        self.weights = np.random.randn(num_input_features,num_classes)\n",
        "        self.bias = np.random.rand(num_classes)\n",
        "\n",
        "    def forward(self,x: np.ndarray):\n",
        "        '''\n",
        "            x: input features\n",
        "            you have random initialized weights and bias\n",
        "            you can access then using `self.weights` and `self.bias`\n",
        "            return an output vector of num_classes size\n",
        "        '''\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "        output = np.matmul(x,self.weights) + self.bias\n",
        "        return output\n",
        "        # YOUR CODE HERE"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgzPxyTsr7uN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d84d8b4-e1f6-4701-f020-229c19707dbf"
      },
      "source": [
        "np.random.seed(0)\n",
        "lc = LinearClassifier()\n",
        "lc.forward(np.random.rand(1,32))\n",
        "# Should be close to:\n",
        "# array([[ 1.30208164,  5.58136003,  0.87793013, -4.7332119 ,  4.81172123]])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.30208164,  5.58136003,  0.87793013, -4.7332119 ,  4.81172123]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ZVgOVzJetuqo"
      },
      "source": [
        "# Part 3: Loss Functions, Gradient descent and Backpropagation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pXryjpctuqy"
      },
      "source": [
        "## Intro\n",
        "\n",
        "Loss Functions tells how \"off\" the output od our model is. Based upon the application, you can use several different loss functions. Formally, A loss function is a function $L:(z,y)\\in\\mathbb{R}\\times Y\\longmapsto L(z,y)\\in\\mathbb{R}$ that takes as inputs the predicted value $z$ corresponding to the real data value yy and outputs how different they are We'll implement L1 loss, L2 loss, Logistic loss, hinge loss and cross entropy loss functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRb8BHotuqy"
      },
      "source": [
        "### **L1 loss**\n",
        "L1 loss is the linear loss function  $L = \\dfrac{1}{2}(y−z) $\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxVh6IL2tuqz"
      },
      "source": [
        "import numpy as np\n",
        "def L1Loss(z,y):\n",
        "    '''\n",
        "        y : True output.\n",
        "        z : Predicted output.\n",
        "        return : L\n",
        "    '''\n",
        "    pass\n",
        "    return 0.5*(y-z)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xy8ZS84cKtQ"
      },
      "source": [
        "### **L2 loss**\n",
        "L2 loss is the quadratic loss function or the least square error function  $L = \\dfrac{1}{2}(y−z)^2 $\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThp5P-KcKtS"
      },
      "source": [
        "import numpy as np\n",
        "def L2Loss(z,y):\n",
        "    '''\n",
        "        y : True output. \n",
        "        z : Predicted output. \n",
        "        return : L\n",
        "    '''\n",
        "    pass\n",
        "    return 0.5*(y-z)**2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2JNLnWYcLSC"
      },
      "source": [
        "### **Hinge Loss**\n",
        "Hinge loss is: $ L = max( 0, 1 - yz ) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ1YM4J-cLSC"
      },
      "source": [
        "import numpy as np\n",
        "def hingeLoss(z,y):\n",
        "    '''\n",
        "        y : True output. \n",
        "        z : Predicted output. \n",
        "        return : L\n",
        "    '''\n",
        "    pass\n",
        "    return max(0,1-y*z)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m15_MjradMNY"
      },
      "source": [
        "### **Cross Entropy Loss**\n",
        "Another very famous loss function is Cross Entropy loss: $ L = −[ylog(z)+(1−y)log(1−z)] $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJLqhszdMNY"
      },
      "source": [
        "import numpy as np\n",
        "def CELoss(z,y):\n",
        "    '''\n",
        "        y : True output. \n",
        "        z : Predicted output. \n",
        "        return : L\n",
        "    '''\n",
        "    pass\n",
        "    return -1*(y*np.log(z) + (1-y)*np.log(1-z))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsRPsfzxyEVL"
      },
      "source": [
        "### **0-1 Loss**\n",
        "Loss Function used by perceptron is: $ \\begin{cases} \n",
        "      0=z-y & z=y \\\\\n",
        "      1=\\dfrac{z-y}{z-y} & z\\neq y\n",
        "   \\end{cases} $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sA7GxLHyEVM"
      },
      "source": [
        "import numpy as np\n",
        "def zeroOneLoss(z,y):\n",
        "    '''\n",
        "        y : True output. \n",
        "        z : Predicted output. \n",
        "        return : L\n",
        "    '''\n",
        "    pass\n",
        "    if(z==y):\n",
        "      return 0\n",
        "    else :\n",
        "      return 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWhbibHcgRR8"
      },
      "source": [
        "## Cost Function\n",
        "The cost function $J$ is commonly used to assess the performance of a model, and is defined with the loss function $L$ as follows:\n",
        "$$\\boxed{J(\\theta)=\\sum_{i=1}^mL(h_\\theta(x^{(i)}), y^{(i)})}$$\n",
        "where $h_\\theta$ is the hypothesis function i.e. the function used to predict the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSbmhW4og97t"
      },
      "source": [
        "lossFunctions = {\n",
        "    \"l1\" : L1Loss,\n",
        "    \"l2\" : L2Loss,\n",
        "    \"hinge\" : hingeLoss,\n",
        "    \"cross-entropy\" : CELoss,\n",
        "    \"0-1\" : zeroOneLoss\n",
        "}\n",
        "\n",
        "def cost(Z : np.ndarray, Y : np.ndarray, loss : str):\n",
        "    '''\n",
        "        Z : a numpy array of predictions.\n",
        "        Y : a numpy array of true values.\n",
        "        return : A numpy array of costs calculated for each example.\n",
        "    '''\n",
        "    loss_func = lossFunctions[loss]\n",
        "    # YOUR CODE HERE\n",
        "    J = loss_func(Z,Y)\n",
        "    return J\n",
        "    # YOUR CODE HERE\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upsN7A0zjGqx"
      },
      "source": [
        "## Gradient Descent and Back Propagation\n",
        "Gradient Descent is an algorithm that minimizes the loss function by calculating it's gradient. By noting $\\alpha\\in\\mathbb{R}$ the learning rate, the update rule for gradient descent is expressed with the learning rate $\\alpha$ and the cost function $J$ as follows:\n",
        "\n",
        "$$\\boxed{ W \\longleftarrow W -\\alpha\\nabla J( W )}$$\n",
        "​\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFCN-fYCqidi"
      },
      "source": [
        "But we need to find the partial derivative of Loss function wrt every parameter to know what is the slight change that we need to apply to our parameters. This becomes particularly hard if we have more than 1 layer in our algorithm. Here's where **Back Propagation** comes in. It's a way to find gradients wrt every parameter using the chain rule. Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to weight ww is computed using chain rule and is of the following form:\n",
        "\n",
        "$$\\boxed{\\frac{\\partial L(z,y)}{\\partial w}=\\frac{\\partial L(z,y)}{\\partial a}\\times\\frac{\\partial a}{\\partial z}\\times\\frac{\\partial z}{\\partial w}}$$\n",
        "​\n",
        " \n",
        "As a result, the weight is updated as follows:\n",
        "\n",
        "$$\\boxed{w\\longleftarrow w-\\alpha\\frac{\\partial L(z,y)}{\\partial w}}$$\n",
        "\n",
        "So, In a neural network, weights are updated as follows:\n",
        "\n",
        "* Step 1: Take a batch of training data.\n",
        "* Step 2: Perform forward propagation to obtain the corresponding loss.\n",
        "* Step 3: Backpropagate the loss to get the gradients.\n",
        "* Step 4: Use the gradients to update the weights of the network.\n",
        "​\n",
        "\n",
        "Bonus Problem\n",
        " \n",
        "Now, Assuming that you know Back Propagation (read a bit about it, if you don't), we'll now implement an image classification model on CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bonus Problem**\n",
        "\n",
        "Now, Assuming that you know Back Propagation (read a bit about it, if you don't), we'll now implement an image classification model on CIFAR-10."
      ],
      "metadata": {
        "id": "sJoG5kkYopRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  \n",
        " \n",
        "# Display the version\n",
        "print(tf.__version__)    \n",
        " \n",
        "# other imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "_4-4RceVsor_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0938c9-67e3-4eea-d60f-70a5ff935d70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyplk5PLEUsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112bb2bb-1afb-4481-ae05-8fadd2f69700"
      },
      "source": [
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        " \n",
        "# Distribute it to train and test set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "# Reduce pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        " \n",
        "# flatten the label values\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQhkATYhEkkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "34321d3b-c2da-43f6-a964-462363b36025"
      },
      "source": [
        "'''visualize data by plotting images'''\n",
        "# YOUR CODE HERE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_img(X,y,index):\n",
        "  plt.imshow(X[index])\n",
        "  plt.xlabel(y[index])\n",
        "\n",
        "show_img(x_train,y_train,0)\n",
        "pass\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf+ElEQVR4nO2dbWyc13Xn/2feOMN3UiIpiZItS36pncaWHdVwnWw3adDCDYo6AYps8iEwiqAqigbYAN0PRhbYZIH9kCw2CfJhkYWSOHUX2byskzRGYbRNjRRGm8K1HDt+ry3LciSKoiiRFDmc4bye/TDjrezc/xUtkkM59/8DBA2fM/d5ztx5zvPM3P+cc8zdIYT41Sez3Q4IIXqDgl2IRFCwC5EICnYhEkHBLkQiKNiFSITcRgab2T0AvgIgC+Dr7v752PPz+bz3FYtBW6vVouMyCMuDWePHKuT4dSwfseWyWWozCx/QLHLNjPjYbPLXHBNEszEfiZTa9jY/VpsfzTKRFxCh3Q6/tpjv0f1F/LfIJDNbJuJHNsPfT3YOAEA7ImN77ERgY6L7C7OwtIJyZS14sCsOdjPLAvifAH4HwGkAT5jZw+7+AhvTVyzi0B3vCdqWlhbosfoy4Td6vMAn45od/dQ2MT5AbTtHB6mtkM0Ht+f6SnQMsnyKFxaXqK3e5K9tbHSE2jKtRnB7rVajY9bW1qitWApfnAGgBX6xqlTLwe0jo8N0DJzvr16rU1sW4fcF4BeXoUH+Pg8M8PMjn+fzUY346LEbQiZ8jsRec9PDF48vfOP7/DDcg8tyJ4Dj7n7C3esAvgPg3g3sTwixhWwk2KcBnLrk79PdbUKIq5ANfWdfD2Z2BMARAOjr69vqwwkhCBu5s88A2HfJ33u7296Eux9198PufjiX59+thBBby0aC/QkAN5jZdWZWAPAxAA9vjltCiM3mij/Gu3vTzD4F4G/Rkd4ecPfnY2PW1tbw/AvhpyydP0/HjZMFUNvBV0Z3toaozUqT1Lba5qpAuRVeIXcr0DGVNb6iWqnyFfJGi0tN5yOaYzEX9rHZ5PvLktVgIP7Vq7K2Sm3Ndvh129oOOiYTUeUaETWhlOPnQZmsaC+0mnRMfz9fjbcM/3RqRK0BAETkvMpaWEFpNsLbASCbC78vjbUqHbOh7+zu/giARzayDyFEb9Av6IRIBAW7EImgYBciERTsQiSCgl2IRNjyX9BdSgZAKUdko8iP664lEtv+KZ4QMjkxTm2lmLQSyWqq1sIJI2sNLgt5ZH+FUiSBJpII421+vJHxcAJQs8H3V8hzPyLJiMgW+JtWq4fnqtHk89Ef2V9ugPtYjIxrWlgezESy6JqRDLVYpuXgAE++Kq9WqK3RDEtssYTDleWLwe3taPaoECIJFOxCJIKCXYhEULALkQgKdiESoaer8WaOooUTEIaGuCs3To8Ft+8o8cyJfJuXWiov8OSUVptf/6qVsO8ZngeD4UiZq1xkFXnp4gofF3nXxofCK8IryzxppR5JaKmSJA0gXldtkJR2atR5okamxV9YPpKQ0yKluAAgR5bPazU+ppDnb2imzRNoauVFagNJogKAPnIaN9tcMbi4GlZkWpF6grqzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhF6Kr3lzDDWFz5kKSKtjJAkiIlhXvOrRdoPAYj0MQGyuUghNFJHrNaOSD8RnSwXScZo1bhE5Vl+jT53LtxlptXgr3qlwpM0Ki0uUw6WIt1daqT9E/hrzhiXjbJ9kU4sq1xm7c+HfcxFWiutReoGVhtcemtHmnYtlbmPS5Xw+VMmUi8ArDXC50A9UmtQd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwoakNzM7CWAFHTWr6e6HowfLGiZGwxLKUJ5LXsVi2JbJcqmjFKnv1mhyGaodyeTqtKH/ZeqRenGtOpfl2h7JKItIXp7jWVkr9XAGW6vF57cSaTXVjNhWVrn/MwthP/IZvr/hMp/7xlneHqx6kUuH1+y8Prh9cnIvHWND4fpuAFBbvEBt5TLPHry4wqW38xfDMuvJU9yPVjYcurU6l+s2Q2f/gLvzd0IIcVWgj/FCJMJGg90B/J2ZPWlmRzbDISHE1rDRj/Hvc/cZM5sE8GMze8ndH7v0Cd2LwBEAKEa+lwshtpYN3dndfab7/zkAPwRwZ+A5R939sLsfLuT0rUGI7eKKo8/MBsxs6I3HAH4XwHOb5ZgQYnPZyMf4KQA/7LZLygH4P+7+N7EB+VwWeybChQiHC1wyGOwPS00Wka4QyUCySLZZrcplnAyR5XYM8TZUAwM8W2v5IhcxRoZ5RtlKpAjk6zPhfZZr/CtUgU8HpvsjWXt5npl38kI4+67mkSKhkay3keEharv7Fq74Ls+GZVavRI61k2dT1ip8Psplfu/sy/N97tsVfm2Tk1N0zNxyWMq78PJZOuaKg93dTwC47UrHCyF6i75EC5EICnYhEkHBLkQiKNiFSAQFuxCJ0NuCk1nD+FA4Gy1XD0s1ANCXD7vZ3xfuawYAtSqXpxqRfl2jo+G+cgDgpEhhvcWvmY1GpBjiIO8Dd2Y+3MsLAF59nWdDza+EX1ukdiGujfTM+/C/O0Rte3dz/x968kRw+z8f59JQs80z/XIZLpWtLM1TW6UcnsehIS6FocWz74pFPq5AsjMBoN/4uGYr/OZcs28PHTO0EO4F+MxrfC50ZxciERTsQiSCgl2IRFCwC5EICnYhEqG3q/G5HCbHdwRt1QW+ap2xsJtl0jYHAKqxWlwWqccWaZPErozVBl9FHh3jCS31Fl9hPnH6DLUtLHMfWX26bKRl1HCR728yF171BYDiAlcMbhjeFdw+O879mFs6R221Cp/jp15+mdoypB1SYyDSumqEJ6Agw0NmZISrQ0PtSLspUqfQ68t0zH6SUNaX5/OrO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESocfSWx5jOyeCtrFB3q4pkwknESwtL9IxjdUy318r1v6JF2RzkpAzOMjrzDXAbS+e4JLRao23EioW+7itEPaxNMBlobEslymfPD5Hbc06P31qI2HpbWKMz4eBy2GNJpdmK3VeC2+V1JqrN/lrtoiUGukOhnwm0josE6m9lwvPY7PGpU0nsi3J1QKgO7sQyaBgFyIRFOxCJIKCXYhEULALkQgKdiES4bLSm5k9AOD3AZxz91/vbhsH8F0A+wGcBPBRd+c62L/tDSAymkXa4zD6IvXA+hHOCgKAXOQal8lE6skRWa6vxNs/nT/Ls8Yq5/mUHRjnElWNq1AoEontpoPTdEwmssNmls/xckT6zGXDdfKGCvx92TF2kNoO3nANtb32iyeo7aWXZ4LbC7mIrOVctm02echkSMYhAOQLfB7b7fB51Y7ofGbh8zSiDK7rzv4XAO55y7b7ATzq7jcAeLT7txDiKuaywd7tt77wls33Aniw+/hBAB/eZL+EEJvMlX5nn3L32e7js+h0dBVCXMVseIHOO8XU6Y/0zOyImR0zs2MrlciXTSHElnKlwT5nZrsBoPs/rSfk7kfd/bC7Hx7q54tOQoit5UqD/WEA93Uf3wfgR5vjjhBiq1iP9PZtAO8HsNPMTgP4LIDPA/iemX0SwOsAPrqeg7XdUV0LF9ezBs9cAsIZSqurvCBfvcGvY80M/4RRrnCpbJnYpvfxafQm39+1O7lQcnAPl2oqa3zc9I23BbcXnH+FWrzIC3eWRsMFQgEAF3gm175du4Pbl1Z5Nt+BX7uB2obHeNbe8NjN1LY4H57/xYu8hVY+Ig9mnGccNtqRbEqeTIlWI3x+R5LoaCuySNLb5YPd3T9OTB+83FghxNWDfkEnRCIo2IVIBAW7EImgYBciERTsQiRCTwtOOhwtC8sT3uIFAJnMUCryIpWDQ1yqOTPPZb7XTs9TWy4f9qMwx/uyrc3x/d0wyeW1D76fy1Cvzrw1VeHfGJoOF/TcuSNcABIAzs3zopKjoxEZqs39L5ACi+fmw1loAJArLlHb/NIstc3M8iy1fD58HowOcy2sWuUCluf4/dEiWlk7IstlLDzOIhmYkTaB/Dhvf4gQ4p2Igl2IRFCwC5EICnYhEkHBLkQiKNiFSISeSm/ZbAajo4NBWzPHpbdyOZyx5Q0uZ1xc4VlNr/+CS03lMpdxSsXwtXH2NZ59N1XkRQinp6+lttE911FbfiWSQkWKcO697U4+5CyXw0pNLh22wDPpVlfDtt39YWkQAOot/rpsIHzeAMDegT3UNjQalhxXLpylY87NXaC2hnG5ca3Oi1giw7Wygb5wFma9GpEUSQFLIzIeoDu7EMmgYBciERTsQiSCgl2IRFCwC5EIPV2Nb7eaWFkKr3Tm6rxWW560ugEvgYZclhsrZb5SPzbEEz9GB8KrptVFvho/uYfXcJu+9d9T23On69T28nFuu3v3eHD70hIfM3UwXLcOADKoUFu9xlfqRz28sr58jq90l+q8Ft7u8fDrAoClFq8Ll791LLi9Gkms+adHHqa206f4a85GWjzFGjOxvJtGrE1ZIzxXLGkM0J1diGRQsAuRCAp2IRJBwS5EIijYhUgEBbsQibCe9k8PAPh9AOfc/de72z4H4I8BvKFDfMbdH1nPAbNEgWhFfvTvRLbIkLZQANAyLr0tcoUHy8uR+mO1sHy1e4TLdb/xgQ9Q296b7qK2H3zzAWrbFUkKydbD9fVmTrzK93fgFmor7rie2gacy6WVhXCvz1I7LIUBQL3KZb7zK9w2OsGThnbs2h/cXi0P0zEZbkKrwJN/YjXoGg0ufVoznNBlzhO9ms1w6G5UevsLAPcEtn/Z3Q91/60r0IUQ28dlg93dHwPAy5kKId4RbOQ7+6fM7Bkze8DM+GczIcRVwZUG+1cBHARwCMAsgC+yJ5rZETM7ZmbHyhX+vUUIsbVcUbC7+5y7t9y9DeBrAGgZFHc/6u6H3f3wYD+v2iKE2FquKNjNbPclf34EwHOb444QYqtYj/T2bQDvB7DTzE4D+CyA95vZIQAO4CSAP1nPwQyAEWWgRbJ4AN4GJ9KJB16N7C9Swm18B28btas/LPXdcfhGOubmu7m8tniOy419TZ6Zd2DvXmprkxe3a5LXfmuucQmzEsmWqzf5uEY1fGq1wGXDV2dOU9uzzx2jtrvv4j7u2BXOOlxeCUuDAEA6RgEAdu7nMms71q6pHpHRiKR7cZ63w6qthJ1sk2xDYB3B7u4fD2z+xuXGCSGuLvQLOiESQcEuRCIo2IVIBAW7EImgYBciEXpacNIdaJMMn2qNSwYFkuWVy/ECf9kMl2Ou38V/3Vss8evf/mv3Bbff9j6e2bb7plup7el//ia1XbOP+7jrXe+mtsLEweD2XP8IHVNZ4xJgdZlnts2dOUVti3NhGa3V4NlrpaFwQU8A2LmTv9enzjxFbVO7p4Pbm5VIlmWVt3Gy1UVqa3k44xAAnGnOAEp94ddW2MVf83IfyQSNRLTu7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEnkpvZoZ8NnzIxUhBwdZaWGYo9ZfomGyGSx2Tkcy2U7M80+jgHaFSfMDed4e3d+ASWmNlldpGhrhUNnHjIWpbzYV7oj3/1BN0TK3K/Vhe5vNxfuYX1JZthaXPYpGfctPXhWUyALj1Rl74spnlmWj57Gh4e4FnRebWeFHJyusz1MZkZQBoRm6rZdKXsH8Hf11TpIdgPh/pD8ddEEL8KqFgFyIRFOxCJIKCXYhEULALkQi9TYRpt1Grhlc6+/u4K1YMr1bmM7wGmre4rTTIW0P9wX/4A2q7+/c+GNw+vHOKjpk78SK1ZSP+L63wGnTzJ/+V2s6shFeE/+Gv/oqOGSzxhIu1Gk8Y2TXFFYPhofBK8munefJMPTIf43v2U9uN734PtaHVF9y8sMTr3VWI+gMAi1Xuozk/h9eqPNGrTFo2eZmrAjeHRQa0uQilO7sQqaBgFyIRFOxCJIKCXYhEULALkQgKdiESYT3tn/YB+EsAU+i0ezrq7l8xs3EA3wWwH50WUB91d16gC4DD0XZSG67NkwisGZYtmh5p8RSp+VXsG6a2Q+/hMk5fPixRvfA0r4G2eOZVaqvVuLSysrhAbaeOv0BtZQ8nB+Vb/FiDOS5FDhd5MsbEGJfeZufOBrc3I22+Kitc5jv1Gk+6AZ6nlnI5XEOvmOPnR7NvktouNPm5UyrxGnr9Qzxpq5QLy4MrlWU6ptkOS4AR5W1dd/YmgD9391sA3AXgz8zsFgD3A3jU3W8A8Gj3byHEVcplg93dZ939Z93HKwBeBDAN4F4AD3af9iCAD2+Vk0KIjfO2vrOb2X4AtwN4HMCUu892TWfR+ZgvhLhKWXewm9kggO8D+LS7v+nLhLs7yNcFMztiZsfM7NhqlddyF0JsLesKdjPLoxPo33L3H3Q3z5nZ7q59N4Bgw2t3P+ruh9398ECpsBk+CyGugMsGu5kZOv3YX3T3L11iehjAfd3H9wH40ea7J4TYLNaT9fZeAJ8A8KyZPd3d9hkAnwfwPTP7JIDXAXz08rtyAGEZrd3kH/Fz+XDNuFak5lcdPDtpaoTXhfvbh/+a2sanwhLP5O5wWygAqFd49lo+H5ZcAGBwgEs8uQyXygaIPLhrMlyzDACqK1wxLWW5jxfmz1Nbox5+b4aKXIKql7n09spTx6ht9qWXqa3WJC2Z8nwOW7H53culSAzwczjTx6XPIpHRxsDn6uZ3XRfcXiqeoGMuG+zu/o8AWM5fOOdTCHHVoV/QCZEICnYhEkHBLkQiKNiFSAQFuxCJ0NOCk3BDux1e2C9EMq+KOVKsL8MLA3qkJVC7zjOvzp8PZ2sBQHk+bCs1eHZSG/x1jY9xOWx0zwS1NVs1aps5E/bRI/lQmQw/DepNLmFmjReqHCiG5VKSwNjZX8wYyWJs1bm8mSHn23KFy431PiLXARjaw+d+tcRbZa20uSy3thq+5+4YPkDH7CRSai7P30vd2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIvZXeYMhYOIuq2MczfJxksA2UwvIOAAwM7aS2SoNnIO0Y4jn3OeJH/eIcHdPO8P1V8lxqmpoKZzUBQLvOZZybbt0b3P7TnzxKx9S9Qm154/JmtczHDQ+Fs/YKOX7KZS3SD22Nv2evzXIZbWkp/J7VbJWOmbiR3wOnRyNZe87f68XzfK4Ka2EJc2A6kqlYCWcVtiPqpe7sQiSCgl2IRFCwC5EICnYhEkHBLkQi9HQ1PmNAIRe+vlRqPMEgS1oQtSP10SoNnsyQzfOkir4CX23N58N+FPp5G6SRYZ6Qc3aer+JXpsOr6gAwue96aps5F64L967feC8dU54/Q20nXuatlVbLPPEjlw3P/8gIr61npD4hAMzOcB9/8XokEaYvPP/DU1zJmRiP+BhRBWyBv9djizzUpifHg9v3jvJz4PgL4YSnWpUneenOLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiES4rPRmZvsA/CU6LZkdwFF3/4qZfQ7AHwOY7z71M+7+SPRgOcPURPj60rhwgY6rtsKSzCrPZYBneGuoXCQZY3iYJx8USGul6iqvQVeK1ARDnduO/fSn1HbgJi7ZnT4dlmQykXp9/X28llw2Im+WSlxqWi2HpbdqlUuizUgLsMES9+Pu22+ktiJJyGlmeW29VoMnrVRPcekts1Kktsn+IWq7/cZ3hceM8i7oT86+FtzebPDXtR6dvQngz939Z2Y2BOBJM/tx1/Zld/8f69iHEGKbWU+vt1kAs93HK2b2IoDprXZMCLG5vK3v7Ga2H8DtAB7vbvqUmT1jZg+YGW+NKoTYdtYd7GY2COD7AD7t7ssAvgrgIIBD6Nz5v0jGHTGzY2Z2bLnCv5MJIbaWdQW7meXRCfRvufsPAMDd59y95e5tAF8DcGdorLsfdffD7n54uJ9X8hBCbC2XDXYzMwDfAPCiu3/pku27L3naRwA8t/nuCSE2i/Wsxr8XwCcAPGtmT3e3fQbAx83sEDpy3EkAf3K5HRUKhmv2he/uI8Zli+OnwlLI3DzPXqu3uFQzOMhf9mqFZ1C12uXg9mzkmrkwzyXFlTKXSdYa3I+sc9vQYHjpZO7sAh1zepXLSW3nkt3UBJcprR3Ovlpc4vXi+gb4ezY6wqWrQpbPf61OJNgclxtXa3x/9XKk5VWbj7t+3y5q27MrPI+nTnOJ9cJ8OCaakRZa61mN/0cAoXc8qqkLIa4u9As6IRJBwS5EIijYhUgEBbsQiaBgFyIRelpwMpszDI+RzDEiJQDA2GQ2bBjgRQPPz/EClmuR9km5Ai82yIa1GzzDrtHiflyschlqIJLltVbhUll1LVxwsh7xsRWxuZO5B1BejrR/Gg4X7hwe5sU5q1W+v/MX+FwNDvLsO8uE72fW5LJtIceLjvZxhRiFAp+r/dfvp7ZqJezLY4+9QMc88/K58L7WuJyrO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESoafSm5khVwwfsjjMc93HB8PXpFyVy1r5Es/+WY703UKLX/9KxcnwkDw/VqvG+6EV+rkf+Ryfj2yWS441D/tSb3C50SOZbcYVKnidS4AtYspHss1Q4HLj0iKX3qp13t9sZDQspeaIJAcAmcjcV8ClrbnzK9S2GMlwXFkNZzH+/T+8xI9FVMq1uqQ3IZJHwS5EIijYhUgEBbsQiaBgFyIRFOxCJEJPpbd221BmBfuyg3Tc4EBYx8mXuC40EElPGhnhUll5mfciKy+HCwCWK5GstzVuGyrwgo1F0lcOAJo1LjnmcuHrdyFyWc/38WwtMz6wP1K4M0NMzRaXhgqlSA++US43LixwyWuFSJHD43zuK5Gec6+c5AVEX3r2FLVNjfNsyqm95LVl+Hm6kxTgnFvhMqTu7EIkgoJdiERQsAuRCAp2IRJBwS5EIlx2Nd7MigAeA9DXff5D7v5ZM7sOwHcA7ADwJIBPuHu0TWu9Dpx+PWyrLfHV86GJ8ApusRRJgOCL+xgf5y+7vMrroC0thW2LF3jixCJfvEW2zVfB286VhlaLr/CjHbbFruqW4Ykw2Ryfq2okacjJonuetIUCgGaFt6hqRerTtSLJNUvl8DjWFQoAFiKKzMnj/A1durBKbfVVfsBdI+HWUDdfO03HMBdfObtMx6znzl4D8Nvufhs67ZnvMbO7AHwBwJfd/XoAiwA+uY59CSG2icsGu3d4o6NhvvvPAfw2gIe62x8E8OEt8VAIsSmstz97ttvB9RyAHwN4FcCS+///sHYaAP/MIYTYdtYV7O7ecvdDAPYCuBPAr633AGZ2xMyOmdmxi2Ve7EAIsbW8rdV4d18C8BMAvwlg1MzeWL3ZC2CGjDnq7ofd/fDIYKTCvhBiS7lssJvZhJmNdh+XAPwOgBfRCfo/7D7tPgA/2ionhRAbZz2JMLsBPGhmWXQuDt9z9782sxcAfMfM/huApwB843I7csuhld8ZtDUKh+m4Wjuc+JFphlsdAUBxhMtJoxP8E8ZYhidqjFfCiQlLC7xd0NJ5Lq9VV/n0t5pczoPza3S7GfZxrcq/QhUKkXp3Oe7/yhpP1KiSr2z5iDo7lAkndwBAO8MlpUaDz2PfQFjCLOZ5vbvRAvfxAEap7d238TZUN916G7Xtv/764PY77+Jy4+kz5eD2f3qVx8Rlg93dnwFwe2D7CXS+vwsh3gHoF3RCJIKCXYhEULALkQgKdiESQcEuRCKYR7KrNv1gZvMA3sh72wmA6wS9Q368GfnxZt5pflzr7hMhQ0+D/U0HNjvm7lxclx/yQ35sqh/6GC9EIijYhUiE7Qz2o9t47EuRH29GfryZXxk/tu07uxCit+hjvBCJsC3Bbmb3mNm/mtlxM7t/O3zo+nHSzJ41s6fN7FgPj/uAmZ0zs+cu2TZuZj82s1e6/49tkx+fM7OZ7pw8bWYf6oEf+8zsJ2b2gpk9b2b/sbu9p3MS8aOnc2JmRTP7FzP7edeP/9rdfp2ZPd6Nm++aWSQ1MoC79/QfgCw6Za0OACgA+DmAW3rtR9eXkwB2bsNxfwvAHQCeu2Tbfwdwf/fx/QC+sE1+fA7Af+rxfOwGcEf38RCAlwHc0us5ifjR0zkBYAAGu4/zAB4HcBeA7wH4WHf7/wLwp29nv9txZ78TwHF3P+Gd0tPfAXDvNvixbbj7YwDeWjf5XnQKdwI9KuBJ/Og57j7r7j/rPl5BpzjKNHo8JxE/eop32PQir9sR7NMALm13uZ3FKh3A35nZk2Z2ZJt8eIMpd5/tPj4LYGobffmUmT3T/Zi/5V8nLsXM9qNTP+FxbOOcvMUPoMdzshVFXlNfoHufu98B4PcA/JmZ/dZ2OwR0ruzoXIi2g68COIhOj4BZAF/s1YHNbBDA9wF82t3fVJqml3MS8KPnc+IbKPLK2I5gnwGw75K/abHKrcbdZ7r/nwPwQ2xv5Z05M9sNAN3/z22HE+4+1z3R2gC+hh7NiZnl0Qmwb7n7D7qbez4nIT+2a066x37bRV4Z2xHsTwC4obuyWADwMQAP99oJMxsws6E3HgP4XQDPxUdtKQ+jU7gT2MYCnm8EV5ePoAdzYmaGTg3DF939S5eYejonzI9ez8mWFXnt1QrjW1YbP4TOSuerAP7zNvlwAB0l4OcAnu+lHwC+jc7HwQY6370+iU7PvEcBvALg7wGMb5Mf/xvAswCeQSfYdvfAj/eh8xH9GQBPd/99qNdzEvGjp3MC4FZ0irg+g86F5b9ccs7+C4DjAP4vgL63s1/9gk6IREh9gU6IZFCwC5EICnYhEkHBLkQiKNiFSAQFuwhiZqNm9pCZvWRmL5rZb263T2JjrKexo0iTrwD4G3f/w+6Pn/q32yGxMaSzi1/CzEbQ+UHJAdcJ8iuDPsaLENcBmAfwTTN7ysy+3v1JsXgHo2AXIXLoFLX4qrvfDmAVneIR4h2Mgl2EOA3gtLu/kcv9EDrBL97BKNjFL+HuZwGcMrObups+COCFbXRJbAJaoBNBzOwQgK+jUyfwBIA/cvfF7fVKbAQFuxCJoI/xQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhH+H4oCiho8cs6GAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJgho2AEBFbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba3f575-6908-4620-87bf-7b6c50296c98"
      },
      "source": [
        "\n",
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "'''\n",
        " calculate total number of classes\n",
        " for output layer\n",
        "'''\n",
        "print(\"number of classes:\", K)\n",
        "''' \n",
        " Build the model using the functional API\n",
        " input layer\n",
        "'''\n",
        "\n",
        "#   YOUR CODE HERE\n",
        "\n",
        "'''Hidden layer'''\n",
        "# YOUR CODE HERE\n",
        "inputs = Input(shape=(32,32,3))\n",
        "y = Conv2D(filters= 32, kernel_size = (3,3), activation = 'relu')(inputs)\n",
        "y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "y = Conv2D(filters= 64, kernel_size = (3,3), activation = 'relu')(inputs)\n",
        "y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "y = Flatten()(y)\n",
        "y = Dense(64,activation = 'relu')(y)\n",
        "pass\n",
        "# YOUR CODE HERE\n",
        " \n",
        "\"\"\"last hidden layer i.e.. output layer\"\"\"\n",
        "# YOUR CODE HERE\n",
        "outputs = Dense(10, activation = 'softmax')(y)\n",
        "pass\n",
        "# YOUR CODE HERE\n",
        "model = Model(inputs = inputs, outputs = outputs)\n",
        "'''model description'''\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of classes: 10\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                921664    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 924,106\n",
            "Trainable params: 924,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLc4Bay65TyA"
      },
      "source": [
        "# Compile\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "# ...\n",
        "# YOUR CODE HERE\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=30)\n",
        "# ..."
      ],
      "metadata": {
        "id": "U0fGsDCRsQrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d82f3a7-f4a3-4c41-a80c-fe674fd2806e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 62s 39ms/step - loss: 1.5255 - accuracy: 0.4406\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 1.2405 - accuracy: 0.5561\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.1186 - accuracy: 0.6032\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 1.0405 - accuracy: 0.6336\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.9813 - accuracy: 0.6552\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.9396 - accuracy: 0.6686\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.9011 - accuracy: 0.6845\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 59s 37ms/step - loss: 0.8633 - accuracy: 0.6955\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.8327 - accuracy: 0.7079\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.8041 - accuracy: 0.7187\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7808 - accuracy: 0.7254\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7498 - accuracy: 0.7374\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7257 - accuracy: 0.7453\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7019 - accuracy: 0.7523\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 57s 37ms/step - loss: 0.6733 - accuracy: 0.7633\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.6498 - accuracy: 0.7721\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.6203 - accuracy: 0.7819\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5954 - accuracy: 0.7912\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5763 - accuracy: 0.7961\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5503 - accuracy: 0.8050\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5280 - accuracy: 0.8123\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5048 - accuracy: 0.8210\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4875 - accuracy: 0.8257\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4637 - accuracy: 0.8358\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4405 - accuracy: 0.8426\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 57s 37ms/step - loss: 0.4290 - accuracy: 0.8475\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 0.4105 - accuracy: 0.8538\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 0.3939 - accuracy: 0.8603\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 0.3736 - accuracy: 0.8685\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 0.3567 - accuracy: 0.8733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e2c197190>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label mapping\n",
        " \n",
        "labels = '''airplane automobile bird cat deerdog frog horseship truck'''.split()\n",
        " \n",
        "# select the image from our test dataset\n",
        "image_number = 0\n",
        " \n",
        "# display the image\n",
        "plt.imshow(x_test[image_number])\n",
        " \n",
        "# load the image in an array\n",
        "n = np.array(x_test[image_number])\n",
        " \n",
        "# reshape it\n",
        "p = n.reshape(1, 32, 32, 3)\n",
        " \n",
        "# pass in the network for prediction and\n",
        "# save the predicted label\n",
        "predicted_label = labels[model.predict(p).argmax()]\n",
        " \n",
        "# load the original label\n",
        "original_label = labels[y_test[image_number]]\n",
        " \n",
        "# display the result\n",
        "print(\"Original label is {} and predicted label is {}\".format(\n",
        "    original_label, predicted_label))"
      ],
      "metadata": {
        "id": "RDq_RE6osSh8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5301ca59-0c0c-4377-b411-9a47055380f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label is cat and predicted label is cat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe7ElEQVR4nO2daYyc13Wm31NfLb1vbLLZXEVJlBVZiSmF1tiJRpGdcaAoCWQDgccewFAAIwqCCIiBzA/BA4w9wPxwBmMb/jHwgB5rrBgeyxrbgoREyNiWgwiGHUnURi3UQnGRSDbZJJu9d+1nflTJQ2nue7vJZlfTvu8DEKy+p+/3nbr1nfqq71vnHHN3CCF+/cmttwNCiM6gYBciERTsQiSCgl2IRFCwC5EICnYhEiG/mslmdgeArwHIAPwPd/9S7Pf7u/O+YaAYPlb8PBftW0xSdHBb9FxkWvR4/Ghxo8feh2P+h20WOxmZAwAxZfbSZFvuR+xo7hd/DbSOydaD04w+6UvzI/bsmKUZcYP5OLNQx1KlEXTykoPdzDIA/w3AxwAcB/C0mT3q7q+wORsGivjCv7s+fDxv0nMVC2E3LccDolqtUFu9UePnKobfjACg0Qz76JFXxXINastl1ASv9fJjgh+zUCwHx7PIS2057n+jWae2Wp2/Zs0mCQrjftTD1ygAoMKOh+UCN+xj7E29WuXXR6MRWcfINZyLvGZVcl0t8KXHYjV8vG//5ETEh0vnFgCH3P2wu1cBPAjgrlUcTwixhqwm2LcCePuCn4+3x4QQVyBrvkFnZveY2X4z2z+/FPlcIoRYU1YT7CcAbL/g523tsXfh7vvcfa+77+3rXtV+oBBiFawm2J8GsNvMdplZEcCnADx6edwSQlxuLvlW6+51M7sXwP9BS3q7391fjs6BoUreX9yX+ESyW1kC37HOgW915/ORHfJLULyswCdVqlVqqzcjPkaktyyyi58n06zJd5hR58pFbBe5GfG/al3B8UZW4nNix2vw9bAm99GImtAVec3yxm25fES5qEXW2PifsE7W2CM6Q5aFfYwpE6v6XO3ujwF4bDXHEEJ0Bn2DTohEULALkQgKdiESQcEuRCIo2IVIhA5/y8XhLLHCufzjjfAca3CpplnjklfWHZFxwJMZmOTVjEg/xUKB2urObc1a5LlFzlevh20WyeTKRWQ+y3hikGdheQ0Alhphie3UOS5PLVS5j/PzfF7mfD36u8LrWDT+Og/0dFNbd4lLaM0cv+ZyURkt7CO/OoAaS76KaG+6swuRCAp2IRJBwS5EIijYhUgEBbsQidDR3XhzR75Bdt2zyG4xSeIoZZH8+HxsWzKS6EASDADQRJh6rFhYjvtRKPJd381XXUdts9Nnqe3sucXwufJ8Vz2HSHJKnV8iS879P3gs7KOXRuicWsYTm6p9fOd/fmaK2k5MTgfH+0r8eTVOhecAwI4xvo4b+vk6duVj5azC13Excgk3iAIRK7elO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESYR3KvYalAcsP8RlETqjHOnDkuCxXrfOEhWKkRlqjQWqFRRJTEJFCipE6aP/q33yM2p75+S+o7eT0ueD4QkRCqze45HXs+BlqO3KCdx8pDY0Hx7eN7aJzvNRPbdU8f10KfRuprV6eD46fmzxJ5/QMcXnw+PxpaiuTWokAMNbP01p6CuFEmEYtLKMCAGviE+nkpTu7EKmgYBciERTsQiSCgl2IRFCwC5EICnYhEmFV0puZHQUwB6ABoO7ue2O/37QcKrmwvDKz2EPnNUh7ouE+Lq8NZFwOy0fqsTUjshyTNWhdPcSz6BYXz1PbT//+EWo7Pc3r9Z2eD5/v2Al+rmMTb1Nb1tVHbY1sgNp6B0aD44Uefrx8F8+iK0VaMnXluHR4thpuKza+bQedU15aoLYjR7j0NjVTprbM+PO+amPYVmhwKc9YXcaI1Hs5dPaPuDvPuRRCXBHoY7wQibDaYHcAPzKzZ8zsnsvhkBBibVjtx/hb3f2EmW0C8GMze9Xdn7jwF9pvAvcAwHA/r/IhhFhbVnVnd/cT7f8nATwM4JbA7+xz973uvrevex2+ii+EALCKYDezXjPrf+cxgD8A8NLlckwIcXlZza12DMDD7a3+PID/5e7/GJtQbxrOLIUzfKZqPOvtiZ//c3D8N3ZzyeUj7w9LPwAwHClu2SSZbQCQI216cjme0dRw3rYooibhyLEj1Da1xDPAvGc4OJ71ceknNzxHbd1Dg9RWLXOpqUraKw0M89dsoI/bJk+dorbZ87zgZH8xfIl3dXOZ763zXFwq9G+itjOn3qK2vtN8jTcPhH3ptkimIinCioisfMnB7u6HAXzgUucLITqLpDchEkHBLkQiKNiFSAQFuxCJoGAXIhE62+stKyE/GC44uHiOv+/UiuGCglOLYSkMABarvDfYQJFntjVJ3622MTicZTxjr1zlEs8ZnryGs3NcAowVRBzeGM7mWmjO0jmj4D5mkUy0aoGvY3khLDWV57kfO8c2UNsikdAAYJJktgGAFcIy5cwUL+aISAHRpQWeEZcV+XUwOcuzDidIttzOUX5951hCXKzFITcJIX6dULALkQgKdiESQcEuRCIo2IVIhI7uxnd19+J9v/X/ZcECAI7/y2t0Xt9geDf+lg+HjwUAPdkxaquSnWIAyOV5UosVwjvTDedJPP2btlPb8wcOUVvfEN+Z3rrz/dTmufDucyGyc96shFtGAUC1GmmxFVmrjCRxvPzCATpnoBRpkdTLk2R6I3XtTp4K14yrE2UFADKygw8Aw/1cnZhp8KSn81PcduTUTHB8y9hmOifPFKVIdpXu7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEjkpvuSyPnsGwpLTz6uvovCWiWuzYdS2dM1rj0sr0ES7L1SKJMI16ONHhlts+TufsuJp3xNr1m0ep7ZnnXqC24T4uyZycDNdPyzsv410qcMkLfBkxH0kKmSF14YZ7+bkip0IjIpWNbgxLswBQqYVfz7Pnw3IXAFikZVd/pE5ePuPhVC3zxJvDbx8Pjm8c4jLf7m3hNmoeuX/rzi5EIijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEWFZ6M7P7AfwxgEl3v7E9NgLgewCuAnAUwCfdnRfZeudYuRyyUjhD6eTpg3Tent/+YHC8d5DX/MrmTlBbox5pkROpdXb47XC23K3D4bp6AICebdTU38vlmK48z+TqjtQ66yqSjK1IXbWtW8ap7ZU336S2YpHX+ZudC6/VVdt20znXXX8DtU1N8curb4BnHZ48NRkctxyv7zY0zGv8zURqyWURya67h/u4NBe+Dg6R6w0Auovhc9XqkSxFavl/fAvAHe8Zuw/A4+6+G8Dj7Z+FEFcwywZ7u9/6e78hcReAB9qPHwDAv1UihLgiuNS/2cfcfaL9+BRaHV2FEFcwq96gc3dH5JuOZnaPme03s/0zM7xmuBBibbnUYD9tZuMA0P4/vAsCwN33ufted987ODhwiacTQqyWSw32RwHc3X58N4BHLo87Qoi1YiXS23cB3A5g1MyOA/gCgC8BeMjMPgvgGIBPruRkZhkKXeG7e7nMCyJWKuG0t0JEgurp5Z8ieiMtjUoZz3rry4f7NX1r3zfpnD/5t/dSW2HhFLUVS5HspRz3cdfVW4Pjk1Mn6ZzyPM9e27xplNqmZrl0WKmGX8+rr+WZitdcyzMfZ557ltoW5uapbXYh7GO9wSWqpaVwOyYAGBoapLaGc6lsYIhn+9Wr4dczy/H+YMcnwh+mqyTLD1hBsLv7p4np95ebK4S4ctA36IRIBAW7EImgYBciERTsQiSCgl2IROhowUmYwbKwBLEYkX/Ki0vB8UKkJ9fcOZ7lhYxLbwXwQoTjQ+FMqTcO8p5tJ49zGxa5HHbs+FFqu2kz73G3dWe4GOWWSf6N5oVDvADnSCnSx26Iy3KHDx8Njo9vCUuDADA9y79hWYtIZafP8F51TbfguEWKQy5GpDfL8esqfKYWvZFClWiGs+yKFr7uAaB6LizbeqRsp+7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSITOSm8OgPTsypxLK+Oj4f5wPV1cevvpAV4ocThSlG/3CM9O6iqFZZdinks1ZyaPUluzwosX7riGF7HMIs+7Z2A4OD46xgtfnpviWWMzkcy2RkTd3Ej6r+UjcmmZZH8B8WyupTLPDqsTJ9k4AJQrPAOzXuf3xw2jm6jNjF9XRQtfPyWL9B30cMZnIVL0Und2IRJBwS5EIijYhUgEBbsQiaBgFyIROrobbwYU8uFkksE+npwy1B+2WZPvVs46Tzw4e56nLIz28yXpLYZ3VBu5cI08ADh68ii1jQ3zemY7r+WtkMr8dHjqmXAbrRMTfOe/vy+8gw8AhQJv8fTyobe4I+Q+0ozcXyqR3fj5BZ4UMjTC2zXVSSLMxGlaEBm9/fx1yWc80aSnh9dELLK2XABQCyfyNBam6ZSxTf3B8XyBt7XSnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsJL2T/cD+GMAk+5+Y3vsiwD+HMCZ9q993t0fW8kJMwtLIZs3hWuntZwkMk4kAWJ8G08k2R+Rw6aNS3aehevkDY7ypIrBAZ4AUegKyycAcFVEeusbDCcGAcD/vP/bwfHFyFrNLk1R2+ISrw1YiFw9m4fDz7s8xevdLZBEIwAYHOCvy6uvvUFtp0+fCY7PRlpGDQ3xJzbQ20dtmXNNtFDl65iRWoQbe/nxBrvCcZSP3L5Xcmf/FoA7AuNfdfc97X8rCnQhxPqxbLC7+xMA+Fu/EOJXgtX8zX6vmR0ws/vNjH8FSwhxRXCpwf51ANcA2ANgAsCX2S+a2T1mtt/M9k9P86//CSHWlksKdnc/7e4Nd28C+AYA2rXA3fe5+1533zs0xBsOCCHWlksKdjMbv+DHTwB46fK4I4RYK1YivX0XwO0ARs3sOIAvALjdzPagVVXuKIC/WMnJcrkczf4ZGObSW70RdrOU55lE1+3aQW37n+GS12zhWmpr2lxwfGwrl9deOfgv1PY7v/dn1PaLn/N5CwuRNknVs8HxyVNv0zmx9/z5GrflwaWh4Vw4y25rN/d95gyX0OoZ3xYa28RtjUY4k24p0uKpvMTr7i1EaujVm1zOq5VPUNumQjijb0sfz6Kr1MNzYnfvZYPd3T8dGP7mcvOEEFcW+gadEImgYBciERTsQiSCgl2IRFCwC5EIHS04mcvl0NsXzl4aHh2l8+oWdrOcK9I5XX0D1DY0xAsKvvX2KWq79YPvD/sxz9tJ9fSHs64AYOLEcWo79Prr1FZv8PZEOVJvcGF2hs7p3zBObTMzXIYa7OPFKN933Y3B8adfeJXOefbVo9R26+1/SG2FIpeoDh86FByfmePPK1YUs7zE5bWdY1zS7e7lBVVHRsLzPM8LcNar4cKXTrJKAd3ZhUgGBbsQiaBgFyIRFOxCJIKCXYhEULALkQgdld7cm2jWw5LH4Agv5LewFC5EuNjgfbeyjL+P7di+jdpef5lnXs0shiW2vl6eYbf9GmrCsdd58cUTJyeo7cMf/iC1LS6GpaH+LVvpnJEtvDjnW1NcKluqcMmx2BvuvzawcTudc1M/f13OnAn3QwOAo8deoLaFpbBMOT3DJbSNGzdS26Dz12VnH5dENw3wHmwFC2cCVmu8v10vkdhy4DGhO7sQiaBgFyIRFOxCJIKCXYhEULALkQgd3Y1v1muYOxfezeyO1PaqlMO7nNbk7pvxXcnREd4+6fXcYWqbnAq38DmX8V3pwT5eW+/6G3lCzuFjvGZcjXdJwvRsWO3YvXs3nbN7F5cMjk3wBJqXX36R2s6dDSenFEtcdRnu44kkx1/mqsCpc7yunZFkqSzSeivWOmwnzzPBjn6eGNSV40ktlXL4+mk2eW3DWp0cj1/2urMLkQoKdiESQcEuRCIo2IVIBAW7EImgYBciEVbS/mk7gL8DMIbWxv4+d/+amY0A+B6Aq9BqAfVJdw/3/GlTqVRw+FBY2tqx+zfovK5cWHprVnmiQL4rIoNEbP39XBrqGwjXtbv++vfROT/50WPUtjjD6931jGyitkPHJ6lt+7ZwUs6u991M55SK/DK4egdP8pme4i/3KwfDCUVN57rhiWmeSDJLkqEAoNzgsu3sdFiK3LSZJ928dY7XpxvZzuXScyXuB5r8uU3Xw8/N8/w6rZDjVcETblZyZ68D+Bt3vwHAhwD8lZndAOA+AI+7+24Aj7d/FkJcoSwb7O4+4e7Pth/PATgIYCuAuwA80P61BwB8fK2cFEKsnov6m93MrgJwE4AnAYy5/zK59xRaH/OFEFcoKw52M+sD8AMAn3P3d30/0d0d5It6ZnaPme03s/1zc7xggBBibVlRsJtZAa1A/467/7A9fNrMxtv2cQDBXSN33+fue919b2zzSwixtiwb7GZmaPVjP+juX7nA9CiAu9uP7wbwyOV3TwhxuVhJ1tvvAvgMgBfN7Pn22OcBfAnAQ2b2WQDHAHxyuQMtVup4/lBYNtpx4y10XhPhbDNjmT8A0OTpP7Nzc9Q2PX2W2jaM7AmO33nHR+icPR+4ntoe+uHD1GbGJZTBwWFq27olLCn1DQzROVk9vL4AMLKZXyLju2rUNtMdlo2ee4HXi5uY5yllXuDtvAY38yzG0WvCUlkWkbUazv14zcPtywDg0CkuDxYzfsylcjk4vhi5vOvN8PUx1+DZgcsGu7v/DADz9PeXmy+EuDLQN+iESAQFuxCJoGAXIhEU7EIkgoJdiEToaMHJcsPw+kx30Ha2wQsAeiEsTeSqvBiiE2kCAHI5btsyzrPN/vXvhDPHugpcctm1k7dd+qM//RS1ff/hf6C2s6f4856YCRcvLJcP0TlFcI1naonbDh3jWXuohmU5H+UZgsObwkUqAaAZqaTY+s4XmdcVPmbTwoUoAaAWaSs20+Dn6irwY3blufS2YOEsu1qBn8ub4fVtRCRb3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCB2V3ioNw+vT4feXR37G+4bt2TkaHN9c5BlIPYVIttZm3n9tfJRnV11zNSlS6LyY4MSZc9R2/4NcXnv2+VeojfW+AwCaCOj8fd0b/HiNEl+PRo5LQ3mEJdZ6RBqq58JzAKArdqVGstTK1fDz9hyfk49kxGVN3tfPy1ymrIPPKzTDPmbGX7NqLex/pMWh7uxCpIKCXYhEULALkQgKdiESQcEuRCJ0dDe+AcN8Lpws8Pizr9N5b7wZbhl1x2/fQOdcs4W36TlyONyaCABu++CN1NZFEhPmqnyH+aF/fJrannvlJLUt1iOthCK7xblC+P27GanJlzO+ixzbtW40eQJQheww1xp8jhmvaVdBJCnE+XPL58lOd8bvcz09PKGlCO5/g2+4o2E81BpkYr3GX5dif7imoOX4eXRnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCIsK72Z2XYAf4dWS2YHsM/dv2ZmXwTw5wDOtH/18+7+WPRk+Tw2jG4M2qbOc/lk4vx0cPznL/BWN43azognXFrZuJkkuwCwLCyHPbX/JTrnH376C2qrNHnNNeS59JbLXfx7dKPCk108Iss1I/JaTPJiLZQKeX7JWcYlTGT8NctH5mVZ+HyxJqNZZH1zzuXBRiTZqBmRDplmt3kzl4/7B8K2N0uRdeIe/JI6gL9x92fNrB/AM2b247btq+7+X1dwDCHEOrOSXm8TACbaj+fM7CAAXjJVCHFFclGfB83sKgA3AXiyPXSvmR0ws/vNjLcWFUKsOysOdjPrA/ADAJ9z91kAXwdwDYA9aN35v0zm3WNm+81sf32Jt0oWQqwtKwp2a1Xh/wGA77j7DwHA3U+7e8PdmwC+ASDYYN3d97n7Xnffm+/mjSCEEGvLssFuZgbgmwAOuvtXLhgfv+DXPgGAb0kLIdadlezG/y6AzwB40cyeb499HsCnzWwPWnLcUQB/sdyBzIzKJIUCl5rq5bCccPT0LJ1TWThIbbfdfB21dQ+NU9tMOSyR/POT++mcsvPMpVqdyzilEs9sa0bqoC0uhlsJxcgiGVnGk94Q6ciEEpG8YllZiNisxGXK7m5euy5PpL5aJKNsbmGB2hoRmbJS56/L4HC4jiIAjI2HbX2RwntLc+E/iT1ybaxkN/5nAEIveVRTF0JcWegbdEIkgoJdiERQsAuRCAp2IRJBwS5EInS04CTc0ayTLKpYxlAWlqGq4NlOk/MVanv2NV7o8c5FLq3MeVjuOHGefzOw1Mezq+qL3P9yhfvf0xORmkjbq9jxLMf9yEXaNcUy2JzIaB65vxQicuN8jWffVetcKmOyXCxjLyahLURab/UNcXltaCNvOVath4/52qs8q7NAshFrVe6f7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhA5LbwBY1pBzuSPLwsX6ms5loUaOF/g7Osmlsvsf4vk9H719b3D8yMkzwXEAWGzEihBGZKguXjgwK3JbD+lhVuzmstbSHJeuYtlhHpGoCiRjK8vz1yx2rixSVDLWx25pcf6i58TONTQ8Qm0bxnjG5NlzU9Q2ffZUePwt3pPw2l27woaIpKg7uxCJoGAXIhEU7EIkgoJdiERQsAuRCAp2IRKho9Jbls8wMjQUtJXLXA5bWApn8hQznv1Vj8hCuUhxyyeeOkBtR06Gs+VmFnjhyKn5JWojyU4AgN7eSLZcpKhgqRR+bvmIXNfVzTPKskhGXL7Aj9kg95F6RPKyiM2d+9io8fWv1sKL3N3FpcjRDRuobXiUy2vVSOZmpRgpHkn6szXzXD5eKIevq2ZEwtadXYhEULALkQgKdiESQcEuRCIo2IVIhGV3482sC8ATAErt3/++u3/BzHYBeBDABgDPAPiMu0f2lwFvOipkF7EUedupNMK7rYWM7wbX+SYyPMdPluvmu+DHSMJLLpLcUa/xHeaYYlAul6ltIdKeKEeeG9ulB4DeIt/17Y4k0ORy3P9iV/h83T18fatVnghzdoonkjTB5+UL4fUYHuilc8ZGwooRAGzezBNhphd4nb+56fPUNj8zHRwfGuHnOnvmbHC8HkkmWsmdvQLgo+7+AbTaM99hZh8C8LcAvuru1wI4D+CzKziWEGKdWDbYvcU7eYKF9j8H8FEA32+PPwDg42vioRDisrDS/uxZu4PrJIAfA3gTwLT7L1uUHgewdW1cFEJcDlYU7O7ecPc9ALYBuAXA9Ss9gZndY2b7zWx/bZG3WBZCrC0XtRvv7tMA/gnAhwEMmf2ysfc2ACfInH3uvtfd9xZ6BlblrBDi0lk22M1so5kNtR93A/gYgINoBf2ftn/tbgCPrJWTQojVs5JEmHEAD5hZhtabw0Pu/vdm9gqAB83sPwN4DsA3lztQs9lEZSksKZUyo/N6iJfNGk8yiXQtQhNcMoolEjRJu6l6NZLA0eDPK9aCKGZrRhJhmPR2/jyXfqYi6zjQxyWqwUg9tgFSC68LXMprNLl0lbdIsk6Jv9iVcviYpTx/XWLnqi/ORGzc//npc9TWJMk6XSUuiZZZnTyLPC9qaePuBwDcFBg/jNbf70KIXwH0DTohEkHBLkQiKNiFSAQFuxCJoGAXIhEsJvFc9pOZnQFwrP3jKIBw6k5nkR/vRn68m181P3a6+8aQoaPB/q4Tm+1393DzNPkhP+THZfdDH+OFSAQFuxCJsJ7Bvm8dz30h8uPdyI9382vjx7r9zS6E6Cz6GC9EIqxLsJvZHWb2mpkdMrP71sOHth9HzexFM3vezPZ38Lz3m9mkmb10wdiImf3YzN5o/z+8Tn580cxOtNfkeTO7swN+bDezfzKzV8zsZTP76/Z4R9ck4kdH18TMuszsKTN7oe3Hf2qP7zKzJ9tx8z0z4xVXQ7h7R/8ByNAqa3U1gCKAFwDc0Gk/2r4cBTC6Due9DcDNAF66YOy/ALiv/fg+AH+7Tn58EcC/7/B6jAO4uf24H8DrAG7o9JpE/OjomgAwAH3txwUATwL4EICHAHyqPf7fAfzlxRx3Pe7stwA45O6HvVV6+kEAd62DH+uGuz8B4L21ke9Cq3An0KECnsSPjuPuE+7+bPvxHFrFUbaiw2sS8aOjeIvLXuR1PYJ9K4C3L/h5PYtVOoAfmdkzZnbPOvnwDmPuPtF+fArA2Dr6cq+ZHWh/zF/zPycuxMyuQqt+wpNYxzV5jx9Ah9dkLYq8pr5Bd6u73wzgDwH8lZndtt4OAa13drTeiNaDrwO4Bq0eARMAvtypE5tZH4AfAPicu7+rOmkn1yTgR8fXxFdR5JWxHsF+AsD2C36mxSrXGnc/0f5/EsDDWN/KO6fNbBwA2v9ProcT7n66faE1AXwDHVoTMyugFWDfcfcftoc7viYhP9ZrTdrnvugir4z1CPanAexu7ywWAXwKwKOddsLMes2s/53HAP4AwEvxWWvKo2gV7gTWsYDnO8HV5hPowJqYmaFVw/Cgu3/lAlNH14T50ek1WbMir53aYXzPbuOdaO10vgngP6yTD1ejpQS8AODlTvoB4LtofRysofW312fR6pn3OIA3APwEwMg6+fFtAC8COIBWsI13wI9b0fqIfgDA8+1/d3Z6TSJ+dHRNAPwWWkVcD6D1xvIfL7hmnwJwCMD/BlC6mOPqG3RCJELqG3RCJIOCXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EImgYBciEf4vt7E0CnHQV6IAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPb6miyTJYAh",
        "outputId": "42d21804-de79-4ace-ea52-8e650eb09e34"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 1.6089 - accuracy: 0.6285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.608885645866394, 0.6284999847412109]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "y_pred=model.predict(x_test)\n",
        "y_pred_classes=[np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"classification report\\n \",classification_report(y_test,y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao6FnBDFKfYK",
        "outputId": "91ddfcda-0391-4520-fb6c-dfddb3dc7139"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.61      0.64      1000\n",
            "           1       0.80      0.71      0.75      1000\n",
            "           2       0.52      0.48      0.50      1000\n",
            "           3       0.43      0.50      0.46      1000\n",
            "           4       0.58      0.59      0.58      1000\n",
            "           5       0.61      0.44      0.51      1000\n",
            "           6       0.69      0.71      0.70      1000\n",
            "           7       0.61      0.77      0.68      1000\n",
            "           8       0.73      0.73      0.73      1000\n",
            "           9       0.68      0.74      0.71      1000\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.63      0.63      0.63     10000\n",
            "weighted avg       0.63      0.63      0.63     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t9EzV0wxLLne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}